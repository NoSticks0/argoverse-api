{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12eac6cd-9a60-4bb6-a078-20284c986b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: C:\\Michael\\10707\\argoverse-api\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6ce9630-820a-4d96-b6fd-7e8e28e4ad62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\michael\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (1.10.2+cu113)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\michael\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from torch) (3.10.0.0)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\michael\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from torch) (0.8)\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdef9423-9f6c-4362-ae61-be2a5a4f2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import random\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "from dataloader import KITTIloader2015 as ls\n",
    "from dataloader import KITTILoader as DA\n",
    "\n",
    "from models import *\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from argoverse.data_loading.stereo_dataloader import ArgoverseStereoDataLoader\n",
    "from argoverse.evaluation.stereo.eval import StereoEvaluator\n",
    "from argoverse.utils.calibration import get_calibration_config\n",
    "from argoverse.utils.camera_stats import RECTIFIED_STEREO_CAMERA_LIST\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "STEREO_FRONT_LEFT_RECT = RECTIFIED_STEREO_CAMERA_LIST[0]\n",
    "STEREO_FRONT_RIGHT_RECT = RECTIFIED_STEREO_CAMERA_LIST[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b124b3-eca6-4f50-886f-b036ad89330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"./\"\n",
    "data_dir = f\"{main_dir}argoverse-stereo_v1.1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35b6bd3-3b88-4b8c-95dc-8e73d9f3ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_data_loader_train = ArgoverseStereoDataLoader(data_dir, \"train\")\n",
    "stereo_data_loader_val = ArgoverseStereoDataLoader(data_dir, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc0577d7-bd64-489e-80b0-6b96c09bc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_ids = os.listdir(f\"{data_dir}/rectified_stereo_images_v1.1/train/\")\n",
    "test_log_ids = os.listdir(f\"{data_dir}/rectified_stereo_images_v1.1/val/\")\n",
    "num_logs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "188ba753-dd48-42e1-9ebb-5ba0fd297da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 5224768\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PSMNet')\n",
    "maxdisp = 192\n",
    "arg_model = 'stackhourglass'\n",
    "epochs = 1\n",
    "loadmodel = './pretrained_sceneflow_new.tar'\n",
    "savemodel = './'\n",
    "no_cuda = False\n",
    "seed = 1\n",
    "\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "all_left_img = []\n",
    "all_right_img = []\n",
    "all_left_disp = []\n",
    "for log_id in train_log_ids:\n",
    "    # Loading the left rectified stereo image paths for the chosen log.\n",
    "    all_left_img += stereo_data_loader_train.get_ordered_log_stereo_image_fpaths(\n",
    "     log_id=log_id,\n",
    "     camera_name=STEREO_FRONT_LEFT_RECT,\n",
    "    )\n",
    "    # Loading the right rectified stereo image paths for the chosen log.\n",
    "    all_right_img += stereo_data_loader_train.get_ordered_log_stereo_image_fpaths(\n",
    "     log_id=log_id,\n",
    "     camera_name=STEREO_FRONT_RIGHT_RECT,\n",
    "    )\n",
    "    # Loading the disparity map paths for the chosen log.\n",
    "    all_left_disp += stereo_data_loader_train.get_ordered_log_disparity_map_fpaths(\n",
    "     log_id=log_id,\n",
    "     disparity_name=\"stereo_front_left_rect_disparity\",\n",
    "    )\n",
    "\n",
    "test_left_img = []\n",
    "test_right_img = []\n",
    "test_left_disp = []\n",
    "for log_id in test_log_ids[:num_logs]:             \n",
    "    # Loading the left rectified stereo image paths for the chosen log.\n",
    "    test_left_img += stereo_data_loader_val.get_ordered_log_stereo_image_fpaths(\n",
    "     log_id=log_id,\n",
    "     camera_name=STEREO_FRONT_LEFT_RECT,\n",
    "    )\n",
    "    # Loading the right rectified stereo image paths for the chosen log.\n",
    "    test_right_img += stereo_data_loader_val.get_ordered_log_stereo_image_fpaths(\n",
    "     log_id=log_id,\n",
    "     camera_name=STEREO_FRONT_RIGHT_RECT,\n",
    "    )\n",
    "    # Loading the disparity map paths for the chosen log.\n",
    "    test_left_disp += stereo_data_loader_val.get_ordered_log_disparity_map_fpaths(\n",
    "     log_id=log_id,\n",
    "     disparity_name=\"stereo_front_left_rect_disparity\",\n",
    "    )\n",
    "\n",
    "TrainImgLoader = torch.utils.data.DataLoader(\n",
    "         DA.myImageFloder(all_left_img,all_right_img,all_left_disp, True), \n",
    "         batch_size= 12, shuffle= True, num_workers= 0, drop_last=False)\n",
    "\n",
    "TestImgLoader = torch.utils.data.DataLoader(\n",
    "         DA.myImageFloder(test_left_img,test_right_img,test_left_disp, False), \n",
    "         batch_size= 8, shuffle= False, num_workers= 0, drop_last=False)\n",
    "\n",
    "if arg_model == 'stackhourglass':\n",
    "    model = stackhourglass(maxdisp)\n",
    "elif arg_model == 'basic':\n",
    "    model = basic(maxdisp)\n",
    "else:\n",
    "    print('no model')\n",
    "\n",
    "if cuda:\n",
    "    model = nn.DataParallel(model)\n",
    "    model.cuda()\n",
    "\n",
    "if loadmodel is not None:\n",
    "    if cuda:\n",
    "        state_dict = torch.load(loadmodel)\n",
    "    else:\n",
    "        state_dict = torch.load(loadmodel, map_location='cpu')\n",
    "        state_dict = {(k if 'module' not in k else k[7:]): v for k, v in state_dict['state_dict'].items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "print('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "\n",
    "def train(imgL,imgR,disp_L):\n",
    "        model.train()\n",
    "        imgL   = Variable(torch.FloatTensor(imgL))\n",
    "        imgR   = Variable(torch.FloatTensor(imgR))   \n",
    "        disp_true = Variable(torch.FloatTensor(disp_L))\n",
    "\n",
    "        if cuda:\n",
    "            imgL, imgR, disp_true = imgL.cuda(), imgR.cuda(), disp_L.cuda()\n",
    "\n",
    "        #---------\n",
    "        mask = (disp_true > 0)\n",
    "        mask.detach_()\n",
    "        #----\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if arg_model == 'stackhourglass':\n",
    "            output1, output2, output3 = model(imgL,imgR)\n",
    "            output1 = torch.squeeze(output1,1)\n",
    "            output2 = torch.squeeze(output2,1)\n",
    "            output3 = torch.squeeze(output3,1)\n",
    "            loss = 0.5*F.smooth_l1_loss(output1[mask], disp_true[mask], size_average=True) + 0.7*F.smooth_l1_loss(output2[mask], disp_true[mask], size_average=True) + F.smooth_l1_loss(output3[mask], disp_true[mask], size_average=True) \n",
    "        elif arg_model == 'basic':\n",
    "            output = model(imgL,imgR)\n",
    "            output = torch.squeeze(output3,1)\n",
    "            loss = F.smooth_l1_loss(output3[mask], disp_true[mask], size_average=True)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.data.ndim == 0:\n",
    "            return loss.data.item()\n",
    "        else:\n",
    "            return loss.data[0]\n",
    "\n",
    "def test(imgL,imgR,disp_true):\n",
    "        model.eval()\n",
    "        imgL   = Variable(torch.FloatTensor(imgL))\n",
    "        imgR   = Variable(torch.FloatTensor(imgR))   \n",
    "        if cuda:\n",
    "            imgL, imgR = imgL.cuda(), imgR.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output3 = model(imgL,imgR)\n",
    "\n",
    "        pred_disp = output3.data.cpu()\n",
    "\n",
    "        #computing 3-px error#\n",
    "        true_disp = copy.deepcopy(disp_true)\n",
    "        index = np.argwhere(true_disp>0)\n",
    "        disp_true[index[0][:], index[1][:], index[2][:]] = np.abs(true_disp[index[0][:], index[1][:], index[2][:]]-pred_disp[index[0][:], index[1][:], index[2][:]])\n",
    "        correct = (disp_true[index[0][:], index[1][:], index[2][:]] < 3)|(disp_true[index[0][:], index[1][:], index[2][:]] < true_disp[index[0][:], index[1][:], index[2][:]]*0.05)      \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return 1-(float(torch.sum(correct))/float(len(index[0])))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    if epoch <= 200:\n",
    "        lr = 0.001\n",
    "    else:\n",
    "        lr = 0.0001\n",
    "    print(lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def main():\n",
    "    max_acc=0\n",
    "    max_epo=0\n",
    "    start_full_time = time.time()\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        total_train_loss = 0\n",
    "        total_test_loss = 0\n",
    "        adjust_learning_rate(optimizer,epoch)\n",
    "           \n",
    "               ## training ##\n",
    "        for batch_idx, (imgL_crop, imgR_crop, disp_crop_L) in enumerate(TrainImgLoader):\n",
    "            start_time = time.time() \n",
    "\n",
    "            loss = train(imgL_crop,imgR_crop, disp_crop_L)\n",
    "            print('Iter %d training loss = %.3f , time = %.2f' %(batch_idx, loss, time.time() - start_time))\n",
    "            total_train_loss += loss\n",
    "        print('epoch %d total training loss = %.3f' %(epoch, total_train_loss/len(TrainImgLoader)))\n",
    "        \n",
    "               ## Test ##\n",
    "\n",
    "        for batch_idx, (imgL, imgR, disp_L) in enumerate(TestImgLoader):\n",
    "            test_loss = test(imgL,imgR, disp_L)\n",
    "            print('Iter %d 3-px error in val = %.3f' %(batch_idx, test_loss*100))\n",
    "            total_test_loss += test_loss\n",
    "\n",
    "\n",
    "        print('epoch %d total 3-px error in val = %.3f' %(epoch, total_test_loss/len(TestImgLoader)*100))\n",
    "        if total_test_loss/len(TestImgLoader)*100 > max_acc:\n",
    "            max_acc = total_test_loss/len(TestImgLoader)*100\n",
    "            max_epo = epoch\n",
    "        print('MAX epoch %d total test error = %.3f' %(max_epo, max_acc))\n",
    "\n",
    "        #SAVE\n",
    "        savefilename = savemodel+'finetune_'+str(epoch)+'.tar'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'train_loss': total_train_loss/len(TrainImgLoader),\n",
    "            'test_loss': total_test_loss/len(TestImgLoader)*100,\n",
    "        }, savefilename)\n",
    "        \n",
    "    print('full finetune time = %.2f HR' %((time.time() - start_full_time)/3600))\n",
    "    print(max_epo)\n",
    "    print(max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "357381d9-6142-467f-814c-a11dfb7a1b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n"
     ]
    }
   ],
   "source": [
    "print(len(TrainImgLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a3d864-98ab-4b2a-86fa-d4bd595cd7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

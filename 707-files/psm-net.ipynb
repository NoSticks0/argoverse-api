{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSM Net Baseline\n",
    "\n",
    "*See for reference: https://github.com/JiaRenChang/PSMNet*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Setup\n",
    "\n",
    "----\n",
    "\n",
    "Ensure you're in <...>/argoverse-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from argoverse.data_loading.stereo_dataloader import ArgoverseStereoDataLoader\n",
    "from argoverse.evaluation.stereo.eval import StereoEvaluator\n",
    "from argoverse.utils.calibration import get_calibration_config\n",
    "from argoverse.utils.camera_stats import RECTIFIED_STEREO_CAMERA_LIST\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "STEREO_FRONT_LEFT_RECT = RECTIFIED_STEREO_CAMERA_LIST[0]\n",
    "STEREO_FRONT_RIGHT_RECT = RECTIFIED_STEREO_CAMERA_LIST[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"/Users/main/Documents/GitHub/argoverse-api/\"\n",
    "data_dir = f\"{main_dir}argoverse-stereo_v1.1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Main Model\n",
    "\n",
    "----\n",
    "\n",
    "Goal: Predict disparity map from pair of stereo images\n",
    "\n",
    "### 2.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should create/tune a PSM net and save it as \"model\"\n",
    "    # I'd say, given the time constraints, it's probably best to take one of the prebuilt ones from their\n",
    "    # Github page and just tune it on the Argo data? If you want to try something else though go for it.\n",
    "\n",
    "    # I think their code is input size invariant because the only operations they do are colvolution and\n",
    "    # spatial pyramid pooling, neither of which should have any sizes hardcoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Evaluation\n",
    "\n",
    " * Probably should add checkpoint code depending on how long this takes to run (e.g. save metrics after every iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_data_loader = ArgoverseStereoDataLoader(data_dir, \"val\")\n",
    "\n",
    "metrics = []\n",
    "lens = []\n",
    "log_ids = [\n",
    "    'f9fa3960-537f-3151-a1a3-37a9c0d6d7f7',\n",
    "    '1d676737-4110-3f7e-bec0-0c90f74c248f',\n",
    "    'da734d26-8229-383f-b685-8086e58d1e05',\n",
    "    '6db21fda-80cd-3f85-b4a7-0aadeb14724d',\n",
    "    '85bc130b-97ae-37fb-a129-4fc07c80cca7',\n",
    "    '33737504-3373-3373-3373-633738571776',\n",
    "    '033669d3-3d6b-3d3d-bd93-7985d86653ea',\n",
    "    'f1008c18-e76e-3c24-adcc-da9858fac145',\n",
    "    '5ab2697b-6e3e-3454-a36a-aba2c6f27818',\n",
    "    'cb762bb1-7ce1-3ba5-b53d-13c159b532c8',\n",
    "    '70d2aea5-dbeb-333d-b21e-76a7f2f1ba1c',\n",
    "    '2d12da1d-5238-3870-bfbc-b281d5e8c1a1',\n",
    "    '64724064-6472-6472-6472-764725145600',\n",
    "    '00c561b9-2057-358d-82c6-5b06d76cebcf',\n",
    "    'cb0cba51-dfaf-34e9-a0c2-d931404c3dd8',\n",
    "    'e9a96218-365b-3ecd-a800-ed2c4c306c78',\n",
    "    '39556000-3955-3955-3955-039557148672'\n",
    "]\n",
    "i = 0\n",
    "for log_id in log_ids:\n",
    "    i += 1\n",
    "    print(f\"Now evaluating log_id :: \\t\\t {i}/{len(log_ids)}\")\n",
    "    left_stereo_img_fpaths = stereo_data_loader.get_ordered_log_stereo_image_fpaths(\n",
    "        log_id=log_id, \n",
    "        camera_name=STEREO_FRONT_LEFT_RECT)\n",
    "    right_stereo_img_fpaths = stereo_data_loader.get_ordered_log_stereo_image_fpaths(\n",
    "        log_id=log_id, \n",
    "        camera_name=STEREO_FRONT_RIGHT_RECT)\n",
    "    disparity_map_fpaths = stereo_data_loader.get_ordered_log_disparity_map_fpaths(\n",
    "        log_id=log_id,\n",
    "        disparity_name=\"stereo_front_left_rect_disparity\")\n",
    "    disparity_obj_map_fpaths = stereo_data_loader.get_ordered_log_disparity_map_fpaths(\n",
    "        log_id=log_id,\n",
    "        disparity_name=\"stereo_front_left_rect_objects_disparity\")\n",
    "    lens += [len(left_stereo_img_fpaths)]\n",
    "\n",
    "    for idx in tqdm(range(len(left_stereo_img_fpaths))):\n",
    "        # Load the testing image and corresponding disparity and foreground disparity maps\n",
    "        stereo_front_left_rect_image = stereo_data_loader.get_rectified_stereo_image(left_stereo_img_fpaths[idx])\n",
    "        stereo_front_right_rect_image = stereo_data_loader.get_rectified_stereo_image(right_stereo_img_fpaths[idx])\n",
    "        stereo_front_left_rect_disparity = stereo_data_loader.get_disparity_map(disparity_map_fpaths[idx])\n",
    "        stereo_front_left_rect_objects_disparity = stereo_data_loader.get_disparity_map(disparity_obj_map_fpaths[idx])\n",
    "\n",
    "        # Apply the model\n",
    "        with torch.no_grad():\n",
    "            left_disparity = model(stereo_front_left_rect_image, stereo_front_right_rect_image)\n",
    "        \n",
    "        left_disparity_pred = np.uint16(left_disparity)\n",
    "        timestamp = int(Path(disparity_map_fpaths[idx]).stem.split(\"_\")[-1])\n",
    "        save_dir_disp = f\"{main_dir}707-files/results/sgm/stereo_output/{log_id}/\"\n",
    "        Path(save_dir_disp).mkdir(parents=True, exist_ok=True)\n",
    "        filename = f\"{save_dir_disp}/disparity_{timestamp}.png\"\n",
    "        cv2.imwrite(filename, left_disparity_pred)\n",
    "\n",
    "    pred_dir = Path(save_dir_disp)\n",
    "    gt_dir = Path(f\"{data_dir}/disparity_maps_v1.1/val/{log_id}\")\n",
    "    save_figures_dir = Path(f\"/tmp/results/sgm/figures/{log_id}/\")\n",
    "    save_figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluator = StereoEvaluator(\n",
    "        pred_dir,\n",
    "        gt_dir,\n",
    "        save_figures_dir,\n",
    "    )\n",
    "    metrics += [evaluator.evaluate()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_metrics = { key : 0 for key in metrics[0] }\n",
    "for i in range(0, len(metrics)):\n",
    "    compiled_metrics = { key : compiled_metrics[key] + lens[i] * metrics[i][key] for key in compiled_metrics }\n",
    "\n",
    "compiled_metrics = { key : compiled_metrics[key] / sum(lens) for key in compiled_metrics }"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5500f37fb1acad4160dec4b6395ea6a4a80d35cfb873ccef7a851c7f11c10c83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

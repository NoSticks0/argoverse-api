{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eac6cd-9a60-4bb6-a078-20284c986b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: C:\\Michael\\10707\\argoverse-api\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ce9630-820a-4d96-b6fd-7e8e28e4ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdef9423-9f6c-4362-ae61-be2a5a4f2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import random\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "from dataloader import KITTIloader2015 as ls\n",
    "from dataloader import KITTILoader as DA\n",
    "\n",
    "from models import *\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from argoverse.data_loading.stereo_dataloader import ArgoverseStereoDataLoader\n",
    "from argoverse.evaluation.stereo.eval import StereoEvaluator\n",
    "from argoverse.utils.calibration import get_calibration_config\n",
    "from argoverse.utils.camera_stats import RECTIFIED_STEREO_CAMERA_LIST\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "STEREO_FRONT_LEFT_RECT = RECTIFIED_STEREO_CAMERA_LIST[0]\n",
    "STEREO_FRONT_RIGHT_RECT = RECTIFIED_STEREO_CAMERA_LIST[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b124b3-eca6-4f50-886f-b036ad89330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"./\"\n",
    "data_dir = f\"{main_dir}argoverse-stereo_v1.1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a35b6bd3-3b88-4b8c-95dc-8e73d9f3ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_data_loader_train = ArgoverseStereoDataLoader(data_dir, \"train\")\n",
    "stereo_data_loader_val = ArgoverseStereoDataLoader(data_dir, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc0577d7-bd64-489e-80b0-6b96c09bc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_ids = os.listdir(f\"{data_dir}/rectified_stereo_images_v1.1/train/\")\n",
    "test_log_ids = os.listdir(f\"{data_dir}/rectified_stereo_images_v1.1/val/\")\n",
    "num_logs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "188ba753-dd48-42e1-9ebb-5ba0fd297da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 3672896\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PSMNet')\n",
    "maxdisp = 192\n",
    "arg_model = 'basic'\n",
    "epochs = 1\n",
    "loadmodel = None\n",
    "savemodel = './'\n",
    "no_cuda = False\n",
    "seed = 1\n",
    "\n",
    "cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "all_left_img = []\n",
    "all_right_img = []\n",
    "all_left_disp = []\n",
    "for log_id in train_log_ids:\n",
    "    # Loading the left rectified stereo image paths for the chosen log.\n",
    "    all_left_img += stereo_data_loader_train.get_ordered_log_stereo_image_fpaths(\n",
    "     log_id=log_id,\n",
    "     camera_name=STEREO_FRONT_LEFT_RECT,\n",
    "    )\n",
    "    # Loading the right rectified stereo image paths for the chosen log.\n",
    "    all_right_img += stereo_data_loader_train.get_ordered_log_stereo_image_fpaths(\n",
    "     log_id=log_id,\n",
    "     camera_name=STEREO_FRONT_RIGHT_RECT,\n",
    "    )\n",
    "    # Loading the disparity map paths for the chosen log.\n",
    "    all_left_disp += stereo_data_loader_train.get_ordered_log_disparity_map_fpaths(\n",
    "     log_id=log_id,\n",
    "     disparity_name=\"stereo_front_left_rect_disparity\",\n",
    "    )\n",
    "\n",
    "test_left_img = []\n",
    "test_right_img = []\n",
    "test_left_disp = []\n",
    "for log_id in test_log_ids[:num_logs]:             \n",
    "    # Loading the left rectified stereo image paths for the chosen log.\n",
    "    test_left_img += stereo_data_loader_val.get_ordered_log_stereo_image_fpaths(\n",
    "     log_id=log_id,\n",
    "     camera_name=STEREO_FRONT_LEFT_RECT,\n",
    "    )\n",
    "    # Loading the right rectified stereo image paths for the chosen log.\n",
    "    test_right_img += stereo_data_loader_val.get_ordered_log_stereo_image_fpaths(\n",
    "     log_id=log_id,\n",
    "     camera_name=STEREO_FRONT_RIGHT_RECT,\n",
    "    )\n",
    "    # Loading the disparity map paths for the chosen log.\n",
    "    test_left_disp += stereo_data_loader_val.get_ordered_log_disparity_map_fpaths(\n",
    "     log_id=log_id,\n",
    "     disparity_name=\"stereo_front_left_rect_disparity\",\n",
    "    )\n",
    "\n",
    "TrainImgLoader = torch.utils.data.DataLoader(\n",
    "         DA.myImageFloder(all_left_img,all_right_img,all_left_disp, True), \n",
    "         batch_size= 12, shuffle= True, num_workers= 0, drop_last=False)\n",
    "\n",
    "TestImgLoader = torch.utils.data.DataLoader(\n",
    "         DA.myImageFloder(test_left_img,test_right_img,test_left_disp, False), \n",
    "         batch_size= 8, shuffle= False, num_workers= 0, drop_last=False)\n",
    "\n",
    "if arg_model == 'stackhourglass':\n",
    "    model = stackhourglass(maxdisp)\n",
    "elif arg_model == 'basic':\n",
    "    model = basic(maxdisp)\n",
    "else:\n",
    "    print('no model')\n",
    "\n",
    "if cuda:\n",
    "    model = nn.DataParallel(model)\n",
    "    model.cuda()\n",
    "\n",
    "if loadmodel is not None:\n",
    "    if cuda:\n",
    "        state_dict = torch.load(loadmodel)\n",
    "    else:\n",
    "        state_dict = torch.load(loadmodel, map_location='cpu')\n",
    "        state_dict = {(k if 'module' not in k else k[7:]): v for k, v in state_dict['state_dict'].items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "print('Number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1, betas=(0.9, 0.999))\n",
    "\n",
    "def train(imgL,imgR,disp_L):\n",
    "        model.train()\n",
    "        imgL   = Variable(torch.FloatTensor(imgL))\n",
    "        imgR   = Variable(torch.FloatTensor(imgR))   \n",
    "        disp_true = Variable(torch.FloatTensor(disp_L))\n",
    "\n",
    "        if cuda:\n",
    "            imgL, imgR, disp_true = imgL.cuda(), imgR.cuda(), disp_L.cuda()\n",
    "\n",
    "        #---------\n",
    "        mask = (disp_true > 0)\n",
    "        mask.detach_()\n",
    "        #----\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if arg_model == 'stackhourglass':\n",
    "            output1, output2, output3 = model(imgL,imgR)\n",
    "            output1 = torch.squeeze(output1,1)\n",
    "            output2 = torch.squeeze(output2,1)\n",
    "            output3 = torch.squeeze(output3,1)\n",
    "            loss = 0.5*F.smooth_l1_loss(output1[mask], disp_true[mask], size_average=True) + 0.7*F.smooth_l1_loss(output2[mask], disp_true[mask], size_average=True) + F.smooth_l1_loss(output3[mask], disp_true[mask], size_average=True) \n",
    "        elif arg_model == 'basic':\n",
    "            output = model(imgL,imgR)\n",
    "            output3 = torch.squeeze(output, 1)\n",
    "            loss = F.smooth_l1_loss(output3[mask], disp_true[mask], size_average=True)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.data.ndim == 0:\n",
    "            return loss.data.item()\n",
    "        else:\n",
    "            return loss.data[0]\n",
    "\n",
    "def test(imgL,imgR,disp_true):\n",
    "        model.eval()\n",
    "        imgL   = Variable(torch.FloatTensor(imgL))\n",
    "        imgR   = Variable(torch.FloatTensor(imgR))   \n",
    "        if cuda:\n",
    "            imgL, imgR = imgL.cuda(), imgR.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output3 = model(imgL,imgR)\n",
    "\n",
    "        pred_disp = output3.data.cpu()\n",
    "\n",
    "        #computing 3-px error#\n",
    "        true_disp = copy.deepcopy(disp_true)\n",
    "        index = np.argwhere(true_disp>0)\n",
    "        disp_true[index[0][:], index[1][:], index[2][:]] = np.abs(true_disp[index[0][:], index[1][:], index[2][:]]-pred_disp[index[0][:], index[1][:], index[2][:]])\n",
    "        correct = (disp_true[index[0][:], index[1][:], index[2][:]] < 3)|(disp_true[index[0][:], index[1][:], index[2][:]] < true_disp[index[0][:], index[1][:], index[2][:]]*0.05)      \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return 1-(float(torch.sum(correct))/float(len(index[0])))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    if epoch <= 200:\n",
    "        lr = 0.001\n",
    "    else:\n",
    "        lr = 0.0001\n",
    "    print(lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def main():\n",
    "    start_full_time = time.time()\n",
    "    for epoch in range(0, epochs):\n",
    "        print('This is %d-th epoch' %(epoch))\n",
    "        total_train_loss = 0\n",
    "        adjust_learning_rate(optimizer,epoch)\n",
    "\n",
    "        ## training ##\n",
    "        for batch_idx, (imgL_crop, imgR_crop, disp_crop_L) in enumerate(TrainImgLoader):\n",
    "            start_time = time.time()\n",
    "\n",
    "            loss = train(imgL_crop,imgR_crop, disp_crop_L)\n",
    "            print('Iter %d training loss = %.3f , time = %.2f' %(batch_idx, loss, time.time() - start_time))\n",
    "            if np.isnan(loss):\n",
    "                total_train_loss += 30\n",
    "            else:\n",
    "                total_train_loss += loss\n",
    "        print('epoch %d total training loss = %.3f' %(epoch, total_train_loss/len(TrainImgLoader)))\n",
    "\n",
    "        #SAVE\n",
    "        savefilename = savemodel+'/checkpoint_'+str(epoch)+'.tar'\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "                    'train_loss': total_train_loss/len(TrainImgLoader),\n",
    "        }, savefilename)\n",
    "\n",
    "    print('full training time = %.2f HR' %((time.time() - start_full_time)/3600))\n",
    "\n",
    "    #------------- TEST ------------------------------------------------------------\n",
    "    total_test_loss = 0\n",
    "    for batch_idx, (imgL, imgR, disp_L) in enumerate(TestImgLoader):\n",
    "        test_loss = test(imgL,imgR, disp_L)\n",
    "        print('Iter %d test loss = %.3f' %(batch_idx, test_loss))\n",
    "        total_test_loss += test_loss\n",
    "\n",
    "    print('total test loss = %.3f' %(total_test_loss/len(TestImgLoader)))\n",
    "    #----------------------------------------------------------------------------------\n",
    "    #SAVE test information\n",
    "    savefilename = savemodel+'testinformation.tar'\n",
    "    torch.save({\n",
    "            'test_loss': total_test_loss/len(TestImgLoader),\n",
    "    }, savefilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "357381d9-6142-467f-814c-a11dfb7a1b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n"
     ]
    }
   ],
   "source": [
    "print(len(TrainImgLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a3d864-98ab-4b2a-86fa-d4bd595cd7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is 0-th epoch\n",
      "0.001\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 603979776 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-192f5eaa18e0>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgL_crop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgR_crop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp_crop_L\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iter %d training loss = %.3f , time = %.2f'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0mtotal_train_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-192f5eaa18e0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(imgL, imgR, disp_L)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0marg_model\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'basic'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimgR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmooth_l1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp_true\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\michael\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Michael\\10707\\argoverse-api\\models\\basic.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, left, right)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mcost0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdres0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mcost0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdres1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcost0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mcost0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdres2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcost0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[0mcost0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdres3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcost0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mcost0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdres4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcost0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\michael\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\michael\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\michael\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\michael\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\michael\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\michael\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\users\\michael\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    584\u001b[0m             )\n\u001b[0;32m    585\u001b[0m         return F.conv3d(\n\u001b[1;32m--> 586\u001b[1;33m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m         )\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 603979776 bytes."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1cbeb-da7a-4602-884d-e0b80e37ae2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
